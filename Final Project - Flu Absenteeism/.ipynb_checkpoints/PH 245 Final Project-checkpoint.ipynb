{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PH 245 Final Project - Flu Absenteeism "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(data.table)\n",
    "\n",
    "prefix = \"../absentee/Combined-data/\"\n",
    "filenames = c(\"absentee_all.csv\",\"absentee-flu.csv\", \"absentee-nonflu.csv\", \"ILIData_CA_201101_201739\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Read 0.0% of 42797568 rows\r",
      "Read 3.1% of 42797568 rows\r",
      "Read 6.0% of 42797568 rows\r",
      "Read 8.9% of 42797568 rows\r",
      "Read 11.7% of 42797568 rows\r",
      "Read 14.5% of 42797568 rows\r",
      "Read 17.5% of 42797568 rows\r",
      "Read 20.4% of 42797568 rows\r",
      "Read 23.4% of 42797568 rows\r",
      "Read 26.4% of 42797568 rows\r",
      "Read 29.4% of 42797568 rows\r",
      "Read 32.3% of 42797568 rows\r",
      "Read 35.2% of 42797568 rows\r",
      "Read 38.1% of 42797568 rows\r",
      "Read 41.1% of 42797568 rows\r",
      "Read 44.1% of 42797568 rows\r",
      "Read 46.8% of 42797568 rows\r",
      "Read 49.9% of 42797568 rows\r",
      "Read 52.9% of 42797568 rows\r",
      "Read 56.0% of 42797568 rows\r",
      "Read 59.1% of 42797568 rows\r",
      "Read 62.2% of 42797568 rows\r",
      "Read 65.3% of 42797568 rows\r",
      "Read 68.2% of 42797568 rows\r",
      "Read 71.0% of 42797568 rows\r",
      "Read 73.7% of 42797568 rows\r",
      "Read 76.5% of 42797568 rows\r",
      "Read 79.6% of 42797568 rows\r",
      "Read 82.7% of 42797568 rows\r",
      "Read 85.8% of 42797568 rows\r",
      "Read 89.0% of 42797568 rows\r",
      "Read 92.0% of 42797568 rows\r",
      "Read 95.1% of 42797568 rows\r",
      "Read 97.9% of 42797568 rows\r",
      "Read 42797568 rows and 9 (of 9) columns from 2.816 GB file in 00:00:51\n"
     ]
    }
   ],
   "source": [
    "# Loading Data (using high-speed data.tables for speed)\n",
    "absenteeData = fread( file=paste(prefix, filenames[1], sep=\"\"), stringsAsFactors=TRUE )\n",
    "\n",
    "# Loading a smaller set of data for school-specific value aggregation\n",
    "aggregationData = fread( file=paste(prefix, filenames[3], sep=\"\"), stringsAsFactors=TRUE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(absenteeData)\n",
    "colnames(absenteeData)\n",
    "\n",
    "# Creating a smaller sample for use until final analysis\n",
    "absenteeData = absenteeData[sample(.N, 10000)]\n",
    "nrow(absenteeData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "head(aggregationData)\n",
    "colnames(aggregationData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "getSchoolData = function(aggregationData, dropColumns, aggregationColumns) {\n",
    "    oldw <- getOption(\"warn\")\n",
    "    options(warn = -1)\n",
    "    \n",
    "    cleanAggregationData = aggregationData[,(dropColumns):=NULL]\n",
    "    groupedSchoolData = cleanAggregationData[,head(.SD, 1),by=aggregationColumns]\n",
    "    \n",
    "    options(warn = oldw)\n",
    "\n",
    "    return(groupedSchoolData)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Dropping irrelevant columns from aggregation data\n",
    "dropColumns = c(\"V1\", \"schoolyr\", \"date\", \"grade\", \"race\", \"absent_nonill\", \"absent_ill\",\n",
    "                \"matchid\", \"month\", \"flusesn\", \"absent_all\", \"dist.n\"\n",
    "               )\n",
    "\n",
    "aggregationColumns = c(\"dist\", \"school\", \"enrolled\")\n",
    "\n",
    "schoolData = getSchoolData(aggregationData, dropColumns, aggregationColumns)\n",
    "\n",
    "print(paste(\"Data collected for\", nrow(schoolData), \"schools\"))\n",
    "head(schoolData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Cleaning data and adding more useful variables\n",
    "\n",
    "absenteeData = absenteeData[,date:=as.Date(absenteeData$date, \"%d%b%Y\")]\n",
    "absenteeData=absenteeData[,month:=as.numeric(format(absenteeData$date, \"%m\"))]\n",
    "absenteeData=absenteeData[,week:=week(date)]\n",
    "absenteeData=absenteeData[,yr:=year(date)]\n",
    "\n",
    "absenteeData$fluseasCDC = ifelse(absenteeData$month <= 4 | absenteeData$month >= 10, 1, 0)\n",
    "\n",
    "absenteeData$dist.n = ifelse(absenteeData$dist == \"OUSD\", 1, 0)\n",
    "\n",
    "absenteeData$grade = as.factor(absenteeData$grade)\n",
    "\n",
    "absenteeData$race <- factor(absenteeData$race, levels = c(\"White\",\"African American\",\n",
    "      \"Asian\",\"Latino\",\"Multiple Ethnicity\",\"Native American\",\"Not Reported\",\n",
    "      \"Pacific Islander\"))\n",
    "\n",
    "# Since WCCUSD has different labeling and fewer races reported that OUSD, \n",
    "# reduce all races to subset for uniformity\n",
    "absenteeData = absenteeData[race %in% c(\"Native American\", \"Multiple Ethnicity\", \"Not Reported\"), \n",
    "                            race := \"Don't know Other\"]\n",
    "\n",
    "# The sum of any row will be 0 if there was no absence \n",
    "# or 1 if there was an absence for any reason\n",
    "absenteeData$absence = absenteeData$absent_nonill + absenteeData$absent_ill\n",
    "\n",
    "# Marking all rows as in flu season or not using ILI definition:\n",
    "# Start of flu season: at least 2 consecutive weeks in which % of medical visits for ILI is > 2%\n",
    "# End of flu season: at least 2 consecutive weeks in which % of medical visits for ILI is < 2%\n",
    "cdph=read.xlsx(file=paste(prefix, filenames[4], sep=\"\"), sheetName=\"ILIData\")\n",
    "\n",
    "cdph$yr=substr(cdph$weekending,1,4)\n",
    "cdph$mon=substr(cdph$weekending,6,7)\n",
    "cdph$day=substr(cdph$weekending,9,10)\n",
    "\n",
    "\n",
    "cdph$twoper=ifelse(cdph$ILIper>2,1,0)\n",
    "cdph=cdph[order(cdph$weekending),]\n",
    "cdph$fluseasCDPH=NA\n",
    "cdph$fluseasCDPH[1]=1\n",
    "for(i in 2:nrow(cdph)){\n",
    "  cdph$fluseasCDPH[i][cdph$twoper[i]==1 & cdph$twoper[i-1]==1]=1\n",
    "  cdph$fluseasCDPH[i][cdph$twoper[i]==0 & cdph$twoper[i-1]==0]=0\n",
    "  cdph$fluseasCDPH[i][cdph$twoper[i]==0 & cdph$twoper[i-1]==1]=cdph$fluseasCDPH[i-1]\n",
    "  cdph$fluseasCDPH[i][cdph$twoper[i]==1 & cdph$twoper[i-1]==0]=cdph$fluseasCDPH[i-1]\n",
    "}\n",
    "\n",
    "# Define peak week\n",
    "cdph$seasno[(cdph$yr>=2011 & cdph$mon<6)]=1011\n",
    "cdph$seasno[(cdph$yr>=2011 & cdph$mon>6)]=1112\n",
    "cdph$seasno[(cdph$yr>=2012 & cdph$mon<6)]=1112\n",
    "cdph$seasno[(cdph$yr>=2012 & cdph$mon>6)]=1213\n",
    "cdph$seasno[(cdph$yr>=2013 & cdph$mon<6)]=1213\n",
    "cdph$seasno[(cdph$yr>=2013 & cdph$mon>6)]=1314\n",
    "cdph$seasno[(cdph$yr>=2014 & cdph$mon<6)]=1314\n",
    "cdph$seasno[(cdph$yr>=2014 & cdph$mon>6)]=1415\n",
    "cdph$seasno[(cdph$yr>=2015 & cdph$mon<6)]=1415\n",
    "cdph$seasno[(cdph$yr>=2015 & cdph$mon>6)]=1516\n",
    "cdph$seasno[(cdph$yr>=2016 & cdph$mon<6)]=1516\n",
    "cdph$seasno[(cdph$yr>=2016 & cdph$mon>6)]=1617\n",
    "cdph$seasno[(cdph$yr>=2017 & cdph$mon<6)]=1617\n",
    "\n",
    "maxili=as.data.frame(aggregate(cdph$ILIper,list(seasno=cdph$seasno),max))\n",
    "maxili.row=apply(as.matrix(maxili[,2]),1,function(x) which(cdph$ILIper==x))\n",
    "cdph$peakwk=0\n",
    "cdph$peakwk[maxili.row]=1\n",
    "    \n",
    "cdph$week=week(ymd(cdph$weekending))\n",
    "    \n",
    "cdph.sub=cdph[,c(\"weekending\",\"fluseasCDPH\",\"peakwk\",\"week\",\"yr\")]\n",
    "cdph.sub=as.data.table(cdph.sub)\n",
    "cdph.sub$yr=as.integer(cdph.sub$yr)\n",
    "    \n",
    "# Merging flu season and peak week indicators into absentee dataset\n",
    "cleanedAbsenteeData=cdph.sub[absenteeData,on=c(\"week\",\"yr\")]\n",
    "\n",
    "# End result\n",
    "head(absenteeData)\n",
    "head(cleanedAbsenteeData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "#### Exploratory Data Analysis (EDA)\n",
    "The first, most important thing to do is examine how many absences ocurred in total. Then, we'll break it down year by year and examine absences.\n",
    "\n",
    "Absences are defined within the absent_nonill and absent_ill columns. Both columns having a 0 means the student was present. A 1 appears in one of the columns if there was an absence.\n",
    "\n",
    "In examining our dataset, some other good things to understand include racial breakdown and grade distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beginning Exploratory Data Analysis\n",
    "summary(absenteeData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pieAbsenceBreakdown = function(data, pieTitle) {\n",
    "    \"Creates a pie chart of the absences and presences in dataset\"\n",
    "    numAbsences = sum(data$absence)\n",
    "    numPresences = length(data$absence) - numAbsences\n",
    "    rawBreakdown = c(numAbsences, numPresences)\n",
    "    \n",
    "    piePercent = paste(round(100*rawBreakdown/sum(rawBreakdown), 2), \"%\", sep=\"\")\n",
    "    \n",
    "    pie(rawBreakdown, \n",
    "        labels=piePercent, \n",
    "        col=rainbow(length(rawBreakdown)),\n",
    "        main=pieTitle\n",
    "       )\n",
    "    \n",
    "    legend(\"topright\", \n",
    "           c(\"Absences\",\"Presences\"), \n",
    "           fill=rainbow(length(rawBreakdown))\n",
    "          )\n",
    "}\n",
    "\n",
    "# Examining total absence/presence breakdown\n",
    "pieAbsenceBreakdown(data=cleanAbsenteeData, pieTitle=\"All Year Absence/Presence breakdown\")\n",
    "\n",
    "\n",
    "# Examining flu-specific absence/presence breakdown\n",
    "# fluData = cleanAbsenteeData[fluSeason==1]\n",
    "\n",
    "#pieAbsenceBreakdown(data=fluData, pieTitle=\"Flu Season Absence/Presence breakdown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a pie chart of ethnicities\n",
    "\n",
    "races = cleanAbsenteeData[,.N,by=\"race\"]\n",
    "piePercent2 = paste(round(100*races$N/sum(races$N), 2), \"%\", sep=\"\")\n",
    "\n",
    "pie(x=races$N, labels=piePercent2, col=rainbow(length(races$race)), cex = 0.4)\n",
    "legend(\"topright\", legend=races$race, fill=rainbow(length(races$race)), cex = 0.6, title=\"Ethnic breakdown\")\n",
    "races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examining overall grade distribution\n",
    "grades = cleanAbsenteeData[,.N,by=\"grade\"][order(grade)]\n",
    "\n",
    "barplot(grades$N, names.arg=grades$grade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpreting Our EDA Results\n",
    "\n",
    "So, we see that we have a relatively small number of absences in our overall dataset (this is good!). Since we have a huge sample size, we'll have plenty of absences to examine.\n",
    "\n",
    "Let's perhaps use PCA to interpret whether race is a good predictor of absences? Or whether the school's stats are?\n",
    "\n",
    "Predicting school level absence based on all of its variables in nonflusesn and in flusesn and based on whether it received the intervention or not? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
