{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PH 245 Final Project - Flu Absenteeism "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(data.table)\n",
    "library(boot)\n",
    "\n",
    "prefix = \"../absentee/Combined-data/\"\n",
    "filenames = c(\"absentee_all.csv\",\"absentee-flu.csv\", \"absentee-nonflu.csv\", \"ILIData_CA_201101_201739.csv\",\n",
    "              \"absentee.RData\"\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data (using high-speed data.tables)\n",
    "absenteeData = fread( file=paste(prefix, filenames[1], sep=\"\"), stringsAsFactors=TRUE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(absenteeData)\n",
    "colnames(absenteeData)\n",
    "\n",
    "# Creating a smaller sample for use until final analysis\n",
    "#absenteeData = absenteeData[sample(.N, 1000000)]\n",
    "nrow(absenteeData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Cleaning data and adding more useful variables\n",
    "\n",
    "absenteeData = absenteeData[,date:=as.Date(absenteeData$date, \"%d%b%Y\")]\n",
    "absenteeData=absenteeData[,month:=as.numeric(format(absenteeData$date, \"%m\"))]\n",
    "absenteeData=absenteeData[,week:=week(date)]\n",
    "absenteeData=absenteeData[,yr:=year(date)]\n",
    "\n",
    "absenteeData$fluseasCDC = ifelse(absenteeData$month <= 4 | absenteeData$month >= 10, 1, 0)\n",
    "\n",
    "absenteeData$dist.n = ifelse(absenteeData$dist == \"OUSD\", 1, 0)\n",
    "\n",
    "absenteeData$grade = as.factor(absenteeData$grade)\n",
    "\n",
    "absenteeData$race <- factor(absenteeData$race, levels = c(\"White\",\"African American\",\n",
    "      \"Asian\",\"Latino\",\"Multiple Ethnicity\",\"Native American\",\"Not Reported\",\n",
    "      \"Pacific Islander\"))\n",
    "\n",
    "# Since WCCUSD has different labeling and fewer races reported that OUSD, \n",
    "# reduce all races to subset for uniformity\n",
    "absenteeData = absenteeData[race %in% c(\"Native American\", \"Multiple Ethnicity\", \"Not Reported\"), \n",
    "                            race := \"Don't know Other\"]\n",
    "\n",
    "# The sum of any row will be 0 if there was no absence \n",
    "# or 1 if there was an absence for any reason\n",
    "absenteeData$absence = absenteeData$absent_nonill + absenteeData$absent_ill\n",
    "\n",
    "# End result\n",
    "head(absenteeData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "#### Exploratory Data Analysis (EDA)\n",
    "The first, most important thing to do is examine how many absences ocurred in total. Then, we'll break it down year by year and examine absences.\n",
    "\n",
    "Absences are defined within the absent_nonill and absent_ill columns. Both columns having a 0 means the student was present. A 1 appears in one of the columns if there was an absence.\n",
    "\n",
    "In examining our dataset, some other good things to understand include racial breakdown and grade distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beginning Exploratory Data Analysis\n",
    "summary(absenteeData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pieAbsenceBreakdown = function(data, pieTitle) {\n",
    "    \"Creates a pie chart of the absences and presences in dataset\"\n",
    "    numAbsences = sum(data$absence)\n",
    "    numPresences = length(data$absence) - numAbsences\n",
    "    rawBreakdown = c(numAbsences, numPresences)\n",
    "    \n",
    "    piePercent = paste(round(100*rawBreakdown/sum(rawBreakdown), 2), \"%\", sep=\"\")\n",
    "    \n",
    "    pie(rawBreakdown, \n",
    "        labels=piePercent, \n",
    "        col=rainbow(length(rawBreakdown)),\n",
    "        main=pieTitle\n",
    "       )\n",
    "    \n",
    "    legend(\"topright\", \n",
    "           c(\"Absences\",\"Presences\"), \n",
    "           fill=rainbow(length(rawBreakdown))\n",
    "          )\n",
    "}\n",
    "\n",
    "# Examining total absence/presence breakdown\n",
    "pieAbsenceBreakdown(data=absenteeData, pieTitle=\"All Year Absence/Presence breakdown\")\n",
    "\n",
    "\n",
    "# Examining flu-specific absence/presence breakdown\n",
    "fluData = absenteeData[fluseasCDC==1]\n",
    "nonFluData = absenteeData[fluseasCDC==0]\n",
    "\n",
    "pieAbsenceBreakdown(data=fluData, pieTitle=\"Flu Season Absence/Presence breakdown\")\n",
    "pieAbsenceBreakdown(data=nonFluData, pieTitle=\"NonFlu Season Absence/Presence breakdown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a pie chart of ethnicities\n",
    "\n",
    "races = absenteeData[,.N,by=\"race\"]\n",
    "piePercent2 = paste(round(100*races$N/sum(races$N), 2), \"%\", sep=\"\")\n",
    "\n",
    "pie(x=races$N, labels=piePercent2, col=rainbow(length(races$race)), cex = 0.4)\n",
    "legend(\"topright\", legend=races$race, fill=rainbow(length(races$race)), cex = 0.6, title=\"Ethnic breakdown\")\n",
    "races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examining overall grade distribution\n",
    "grades = absenteeData[,.N,by=\"grade\"][order(grade)]\n",
    "\n",
    "barplot(grades$N, names.arg=grades$grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sixth graders are all from one district - drop all sixth graders\n",
    "sixthGraders = absenteeData[grade==6]\n",
    "unique(sixthGraders$dist)\n",
    "\n",
    "head(sixthGraders)\n",
    "\n",
    "fullNumRows = nrow(absenteeData)\n",
    "absenteeData = absenteeData[grade != 6]\n",
    "print(paste(\"Lost\", (fullNumRows-nrow(absenteeData)), \"rows in eliminating sixth graders.\", \n",
    "            nrow(absenteeData), \"rows remain\")\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpreting Our EDA Results\n",
    "\n",
    "So, we see that we have a relatively small number of absences in our overall dataset (this is good!). Since we have a huge sample size, we'll have plenty of absences to examine.\n",
    "\n",
    "The first thing we did is examine overall number of absences during flu season versus during the nonflu season. As one would expect, flu season had slightly a slightly greater percentage of students absent.\n",
    "\n",
    "In the rest of our EDA, we explored the ethnic breakdown and grade distributions of our dataset. One thing to note is that our subject population is quite different in terms of ethnic breakdown from the entire United States, so our projects extensibility to other populations with different breakdowns is a bit less certain.\n",
    "\n",
    "One thing to note is that our 6th grade population is so small because only one of the two school districts contributed data to that bin, so for this analysis, we'll proceed analyzing only grades K-5. \n",
    "\n",
    "\n",
    "#### Analyzing Absenteeism Variation among Matched Schools\n",
    "To continue, let's try to understand how much variation in absenteeism there was between matched schools during the nonflu season. This will be important as a baseline for analyzing the variance between the same matched schools during flu season when the intervention took place. Schools that were matched have matchid's that are *not* 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculating the average percentage of absences per school\n",
    "# For now, we'll only include the intervention time period\n",
    "nonFluDataInterventionTime = nonFluData[nonFluData$yr > 2014 | nonFluData$schoolyr == \"2014-15\"]\n",
    "\n",
    "nonFluAbsenceAverages = nonFluDataInterventionTime[,.(absenceAverage=mean(absence)),by=c(\"matchid\", \"dist\", \"school\")][order(matchid, dist)]\n",
    "head(nonFluAbsenceAverages)\n",
    "tail(nonFluAbsenceAverages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop schools that were not matched by the matching algorithm and group by matchid\n",
    "nonFluMatchedAbsenceAverages = nonFluAbsenceAverages[matchid != 0][order(matchid, dist)]\n",
    "head(nonFluMatchedAbsenceAverages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's find the baseline difference between the two groups for each matched school\n",
    "\n",
    "OUSDNonFlu = nonFluMatchedAbsenceAverages[dist==\"OUSD\"][order(matchid)]\n",
    "WCCUSDNonFlu = nonFluMatchedAbsenceAverages[dist==\"WCCUSD\"][order(matchid)]\n",
    "\n",
    "differenceNonFlu = OUSDNonFlu[,difference:=(OUSDNonFlu$absenceAverage - WCCUSDNonFlu$absenceAverage)][,c(\"matchid\", \"difference\")]\n",
    "head(differenceNonFlu)\n",
    "barplot(differenceNonFlu$difference)\n",
    "\n",
    "print(\"Mean difference in percentage of absences between matched pairs of schools during nonflu season\")\n",
    "mean(differenceNonFlu$difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's repeat the same set of steps to analyze whether the intervention seemed to have any effect.\n",
    "# We would expect OUSD, which had the intervention, to have absenteeism less impacted by illness. \n",
    "# On the other hand WCCUSD, which did not have any intervention\n",
    "# would have greater absenteeism as flu became more prevalent during flu season. \n",
    "# Thus, we would expect a downward shift in the barplot\n",
    "fluDataInterventionTime = fluData[fluData$yr > 2014 | fluData$schoolyr == \"2014-15\"]\n",
    "\n",
    "\n",
    "fluAbsenceAverages = fluDataInterventionTime[,.(absenceAverage=mean(absence)),by=c(\"matchid\", \"dist\", \"school\")][order(matchid, dist)]\n",
    "fluMatchedAbsenceAverages = fluAbsenceAverages[matchid != 0][order(matchid, dist)]\n",
    "OUSDFlu = fluMatchedAbsenceAverages[dist==\"OUSD\"][order(matchid)]\n",
    "WCCUSDFlu = fluMatchedAbsenceAverages[dist==\"WCCUSD\"][order(matchid)]\n",
    "\n",
    "differenceFlu = OUSDFlu[,difference:=(OUSDFlu$absenceAverage - WCCUSDFlu$absenceAverage)][,c(\"matchid\", \"difference\")]\n",
    "head(differenceFlu)\n",
    "barplot(differenceFlu$difference, col=\"black\")\n",
    "\n",
    "print(\"Mean difference in percentage of absences between matched pairs of schools during flu season\")\n",
    "mean(differenceFlu$difference)\n",
    "\n",
    "# Calculate the percentage of schools where expected \"downward shift\" during flu season occurred\n",
    "print(\"Percentage of matched pairs with expected downward shift:\")\n",
    "sum(differenceFlu$difference < differenceNonFlu$difference)/length(differenceFlu$difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpreting the result\n",
    "\n",
    "This is... mildly worrying, if I'm interpreting the data correctly, though the test we ran was rather informal and intended to understand whether the data would fit to our intuitions. However, it seems as if schools receiving the intervention actually had a larger increase in absenteeism during the flu season vs rest of the year compared to the matched control group which did not receive the intervention. While our analysis did not look at illness specific data (which is pretty important to making an actual conclusion), the trends in the data are very counterintuitive. \n",
    "\n",
    "\n",
    "#### Moving Forward\n",
    "Nevertheless, we'll move on to fitting statistical models for linear and logistic regression in an attempt to be able to predict how certain factors affect all-cause and illness specific absenteeism. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we're generating predictions with regression, need to bring in other school-specific variables to fit on\n",
    "\n",
    "getSchoolData = function(aggregationData, dropColumns, aggregationColumns) {\n",
    "    oldw <- getOption(\"warn\")\n",
    "    options(warn = -1)\n",
    "    \n",
    "    cleanAggregationData = aggregationData[,(dropColumns):=NULL]\n",
    "    groupedSchoolData = cleanAggregationData[,head(.SD, 1),by=aggregationColumns]\n",
    "    \n",
    "    options(warn = oldw)\n",
    "    \n",
    "    print(paste(\"Data collected for\", nrow(groupedSchoolData), \"schools\"))\n",
    "\n",
    "    return(groupedSchoolData)\n",
    "}\n",
    "\n",
    "# Dropping irrelevant columns (for specific schools) from aggregation data\n",
    "dropColumns = c(\"V1\", \"schoolyr\", \"date\", \"grade\", \"race\", \"absent_nonill\", \"absent_ill\",\n",
    "                \"matchid\", \"month\", \"flusesn\", \"absent_all\", \"weekending\", \"peakwk\", \"week\", \"yr\",\n",
    "                \"fluseasCDPH\", \"fluseasCDC\"\n",
    "               )\n",
    "\n",
    "aggregationColumns = c(\"dist\", \"school\", \"enrolled\") # Unique identifying key for a school\n",
    "\n",
    "#load(file = paste(prefix, filenames[5], sep=\"\"))\n",
    "attach(paste(prefix, filenames[5], sep=\"\")); \n",
    "flu = flu; \n",
    "detach()\n",
    "\n",
    "schoolData = getSchoolData(aggregationData=flu, dropColumns=dropColumns, aggregationColumns=aggregationColumns)\n",
    "head(schoolData)\n",
    "colnames(schoolData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging school level data into our set of patients  \n",
    "combinedFluDataInterventionTime = merge(x=fluDataInterventionTime[matchid!=0,!c(\"schoolyr\", \"date\", \"absence\")],\n",
    "                                        y=schoolData, \n",
    "                                        by=c(\"dist\", \"school\", \"dist.n\")\n",
    "                                       )\n",
    "head(combinedFluDataInterventionTime)\n",
    "colnames(combinedFluDataInterventionTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fitting logistic regression for illness-specific absenteeism and nonspecific absenteeism\n",
    "\n",
    "glm.log.ill = glm(absent_ill~., data=combinedFluDataInterventionTime[,!c(\"dist\", \"school\", \"absent_nonill\", \"matchid\")])\n",
    "glm.log.nonill = glm(absent_nonill~., data=combinedFluDataInterventionTime[,!c(\"dist\", \"school\", \"absent_ill\", \"matchid\")])\n",
    "\n",
    "summary(glm.log.ill)\n",
    "summary(glm.log.nonill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Cross-Validation to estimate prediction error of our two models\n",
    "\n",
    "oldw <- getOption(\"warn\")\n",
    "options(warn = -1)\n",
    "\n",
    "cv.log.ill.predError = cv.glm(data=combinedFluDataInterventionTime[,!c(\"dist\", \"school\", \"absent_nonill\", \"matchid\")],\n",
    "                              glmfit = glm.log.ill,\n",
    "                              K=2\n",
    "                             )$delta\n",
    "\n",
    "cv.log.nonill.predError = cv.glm(data=combinedFluDataInterventionTime[,!c(\"dist\", \"school\", \"absent_ill\", \"matchid\")],\n",
    "                              glmfit = glm.log.nonill, \n",
    "                              K=2\n",
    "                             )$delta\n",
    "\n",
    "options(warn = oldw)\n",
    "\n",
    "cv.log.ill.predError\n",
    "cv.log.nonill.predError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Interpretation\n",
    "\n",
    "Though our prediction accuracies are actually very good, its important to recognize how biased our data was to begin with. We started with a dataset composed of < 5% absences, so simply guessing \"present\" every time, a naive model could still get a 95%+ accuracy. This model, thus, is able to pick up on some of the variables which are important to the classification but it has a biased view of which variables are extremely important because of how skewed the data is to one class. That said, dist.n *is* thankfully one of the significant predictors, though that should be taken with a grain of salt due to the above. \n",
    "\n",
    "To further explore whether Shoo-the-flu had an impact:\n",
    "\n",
    "#### Multiple Linear Regression on All-Cause and Illness-Specific School-level Absenteeism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Having fit a logistic regression model, a regularized multiple linear regression model may now help us discern\n",
    "# effects of many of these variables on absenteeism percentage by school\n",
    "\n",
    "granularSchoolAbsenceAverages = absenteeData[,.(absenceAverage=mean(absence)*100, yr=yr, \n",
    "                                                illnessAbsenceAverage=mean(absent_ill)*100),\n",
    "                                             by=c(\"matchid\", \"dist\", \"school\", \"schoolyr\", \"fluseasCDC\")][order(matchid, dist)]\n",
    "head(granularSchoolAbsenceAverages)\n",
    "tail(granularSchoolAbsenceAverages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging school level data into our set of all-cause absenteeism  \n",
    "combinedGranularSchoolAbsenceAverages = merge(x=granularSchoolAbsenceAverages,\n",
    "                                              y=schoolData,\n",
    "                                              by=c(\"dist\", \"school\")\n",
    "                                             )\n",
    "\n",
    "head(combinedGranularSchoolAbsenceAverages)\n",
    "tail(combinedGranularSchoolAbsenceAverages)\n",
    "colnames(combinedGranularSchoolAbsenceAverages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marking rows that schools were under intervention - the hope is of course that intervention contributes significantly to each type of absenteeism predictions\n",
    "\n",
    "combinedGranularSchoolAbsenceAverages = combinedGranularSchoolAbsenceAverages[\n",
    "    ,\"intervention\":= ifelse( (yr>2014|schoolyr==\"2014-2015\"), dist.n, 0)]\n",
    "\n",
    "print(\"Percentage of all rows under intervention: \")\n",
    "mean(combinedGranularSchoolAbsenceAverages$intervention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm.linReg.absenceAverage = glm(absenceAverage~., data=combinedGranularSchoolAbsenceAverages[,!c(\"dist\", \"school\", \"matchid\", \"illnessAbsenceAverage\")])\n",
    "\n",
    "glm.linReg.illnessAbsenceAverage = glm(illnessAbsenceAverage~., data=combinedGranularSchoolAbsenceAverages[,!c(\"dist\", \"school\", \"matchid\", \"absenceAverage\")])\n",
    "\n",
    "summary(glm.linReg.absenceAverage)\n",
    "summary(glm.linReg.illnessAbsenceAverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cross Validation Linear Regression Prediction Error for all cause absenteeism:\")\n",
    "cv.linReg.absenceAverage.predError = cv.glm(data=combinedGranularSchoolAbsenceAverages[,!c(\"dist\", \"school\", \"matchid\", \"illnessAbsenceAverage\")],\n",
    "                              glmfit = glm.linReg.absenceAverage,\n",
    "                              K=2\n",
    "                             )$delta\n",
    "\n",
    "cv.linReg.absenceAverage.predError[1]\n",
    "\n",
    "print(\"Compare to the mean proportionof all-cause absenteeism across schools:\")\n",
    "mean(combinedGranularSchoolAbsenceAverages$absenceAverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cross Validation Linear Regression Prediction Error for illness-specific absenteeism:\")\n",
    "cv.linReg.absenceAverage.predError = cv.glm(data=combinedGranularSchoolAbsenceAverages[,!c(\"dist\", \"school\", \"matchid\", \"absenceAverage\")],\n",
    "                              glmfit = glm.linReg.illnessAbsenceAverage,\n",
    "                              K=2\n",
    "                             )$delta\n",
    "\n",
    "cv.linReg.absenceAverage.predError[1]\n",
    "\n",
    "print(\"Compare to the mean proportion of illness-specific absenteeism across schools:\")\n",
    "mean(combinedGranularSchoolAbsenceAverages$illnessAbsenceAverage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpreting our linear regression\n",
    "\n",
    "So, in this case, based on our cross validation predictions, our linear regression model isn't awful, but it isn't great either at using these school level variables to detect either type of absenteeism, with significant residuals. Unfortunately, we are no closer to discovering how important our intervention variable really is, and can only note that it also was a significant contributor to the regression combination, but since every other variable was as well... that doesn't say much. Our regression does, however, allow us to predict (albeit with a very large margin of error) average absenteeism over any given time period at the school level. This, of course, has the potential to highlight schools in areas that require "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
